{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important libraries for pytest \n",
    "import pytest\n",
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest\n",
    "# This will run pytest \n",
    "def test_firstprogram1(): \n",
    "    print(\"Hello Pytest 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts =======================================\u001b[0m\n",
      "platform win32 -- Python 3.7.3, pytest-5.4.3, py-1.8.0, pluggy-0.12.0\n",
      "rootdir: C:\\Users\\Rahul Maurya\\Desktop\n",
      "plugins: arraydiff-0.3, doctestplus-0.3.0, openfiles-0.3.2, remotedata-0.3.1\n",
      "collected 2 items\n",
      "\n",
      "tmp2i5gw_p2.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.11s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -v\n",
    "# Here adding -v give you more details about testing or give metadata\n",
    "def test_firstprogram2(): \n",
    "    print(\"Hello Pytest 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Pytest 1\n",
      "\u001b[32m.\u001b[0mHello Pytest 2\n",
      "\u001b[32m.\u001b[0mHello Pytest 3\n",
      "\u001b[32m.\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.05s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -s\n",
    "# Here adding -s give you output and logs but not metadata\n",
    "def test_firstprogram3(): \n",
    "    print(\"Hello Pytest 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts =======================================\u001b[0m\n",
      "platform win32 -- Python 3.7.3, pytest-5.4.3, py-1.8.0, pluggy-0.12.0\n",
      "rootdir: C:\\Users\\Rahul Maurya\\Desktop\n",
      "plugins: arraydiff-0.3, doctestplus-0.3.0, openfiles-0.3.2, remotedata-0.3.1\n",
      "collected 4 items\n",
      "\n",
      "tmp_rkrz6_k.py Hello Pytest 1\n",
      "\u001b[32m.\u001b[0mHello Pytest 2\n",
      "\u001b[32m.\u001b[0mHello Pytest 3\n",
      "\u001b[32m.\u001b[0mHave a good day\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.12s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -v -s\n",
    "# Adding -v and -s give you metadata and logs both\n",
    "def test_firstprogram4():\n",
    "    print(\"Have a good day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m4 deselected\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k SecondProgram\n",
    "# Adding -k work as a regular expression run only method which have SecondProgram in their name \n",
    "def test_SecondProgram():\n",
    "    a=4\n",
    "    b=6\n",
    "    assert a+2 ==6, \"Please check again something is wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                        [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m5 passed\u001b[0m, \u001b[33m1 deselected\u001b[0m\u001b[32m in 0.06s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k test_firstprogram\n",
    "# Adding -k work as a regular expression run only method which have SecondProgram in their name\n",
    "def test_firstprogram5():\n",
    "    print(\"Have a good day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# py.test command will run all pytest files in a directory in cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# py.test File name will run only a specific file in cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any pytest file must have start with test_ or end with test_\n",
    "# All codes in pytest must be in method only \n",
    "# Method name start from test\n",
    "# Method name should make a sense so that we can apply regular expression easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                      [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m7 passed\u001b[0m\u001b[32m in 0.13s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest\n",
    "@pytest.mark.smoke\n",
    "def test_firstprogram6():\n",
    "    print(\"Have a good day\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                           [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m6 deselected\u001b[0m\u001b[32m in 0.04s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -m smoke\n",
    "# Adding -m run only the method which are marked with @pytest.mark.smoke  \n",
    "@pytest.mark.smoke\n",
    "def test_firstprogram7():\n",
    "    print(\"Have a good day\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33ms\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                    [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m8 passed\u001b[0m, \u001b[33m1 skipped\u001b[0m\u001b[32m in 0.07s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest\n",
    "# Adding @pytest.mark.skip will skip or pass the method while running all the files\n",
    "@pytest.mark.skip\n",
    "def test_firstprogram8():\n",
    "    print(\"Have a good day\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33ms\u001b[0m\u001b[33mx\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                   [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m8 passed\u001b[0m, \u001b[33m1 skipped\u001b[0m, \u001b[33m1 xfailed\u001b[0m\u001b[32m in 0.17s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest\n",
    "# Adding @pytest.mark.xfail will run the method but not show you any error if any \n",
    "@pytest.mark.xfail\n",
    "def test_firstprogram9():\n",
    "    a=5\n",
    "    b=6\n",
    "    assert a+b==12\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m\u001b[33m\u001b[1m10 deselected\u001b[0m\u001b[33m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k setup -s\n",
    "@pytest.fixture()\n",
    "# Adding @pytest.fixture() will execute this method first and later the method in which this method is called\n",
    "# While adding yield will execute other method first in which this method called and then run this method\n",
    "def setup():\n",
    "    print(\"This will execute first\")\n",
    "    yield \n",
    "    print(\"This will execute at last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will execute first\n",
      "This will execute steps in fixtures demo\n",
      "Hi\n",
      "\u001b[32m.\u001b[0mThis will execute at last\n",
      "\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m10 deselected\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k test_Fixture_Demo_0 -s\n",
    "def test_Fixture_Demo_0(setup):\n",
    "    print(\"This will execute steps in fixtures demo\")\n",
    "    print(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33ms\u001b[0m\n",
      "\u001b[32m\u001b[33m1 skipped\u001b[0m, \u001b[33m11 deselected\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k test_Fixture_Demo1 -s\n",
    "# By creating another class name as conftest and declare some method there and you can run here in method where it is called\n",
    "@pytest.mark.skip\n",
    "def test_Fixture_Demo1(setup1): #setup1 is declared in conftest class or notebook name is conftest\n",
    "    print(\"This will execute steps in fixtures demo\")\n",
    "    print(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m\u001b[33m\u001b[1m14 deselected\u001b[0m\u001b[33m in 0.02s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k setup -s\n",
    "@pytest.fixture()\n",
    "def setup2():\n",
    "    print(\"This will execute first throgh class\")\n",
    "    yield\n",
    "    print(\"I will execute at last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will execute first throgh class\n",
      "This will execute steps in fixtures demo throgh class\n",
      "\u001b[32m.\u001b[0mI will execute at last\n",
      "This will execute first throgh class\n",
      "This will execute steps in fixtures demo throgh class\n",
      "\u001b[32m.\u001b[0mI will execute at last\n",
      "\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m12 deselected\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k test_Fixture_Demo_throgh_class -s\n",
    "@pytest.mark.usefixtures(\"setup2\")\n",
    "# By using class here you can use define method in conftest class or here in all method inside the class using self keyword\n",
    "class Testexamples:\n",
    "    def test_Fixture_Demo_throgh_class1(self):\n",
    "        print(\"This will execute steps in fixtures demo throgh class\")\n",
    "    def test_Fixture_Demo_throgh_class2(self):\n",
    "        print(\"This will execute steps in fixtures demo throgh class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m\u001b[33m\u001b[1m14 deselected\u001b[0m\u001b[33m in 0.02s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k setup -s\n",
    "@pytest.fixture(scope=\"class\")\n",
    "# Giving scope=\"class\" here will run code after yield just once but if you don't do this it run after every step see above case\n",
    "def setup3():\n",
    "    print(\"This will execute first throgh class\")\n",
    "    yield\n",
    "    print(\"I will execute at last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will execute first throgh class\n",
      "This will execute steps in fixtures demo throgh class\n",
      "\u001b[32m.\u001b[0mThis will execute steps in fixtures demo throgh class\n",
      "\u001b[32m.\u001b[0mI will execute at last\n",
      "\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m12 deselected\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k test_Fixture_Demo_throgh_class -s\n",
    "@pytest.mark.usefixtures(\"setup3\")\n",
    "class Testexamples:\n",
    "    def test_Fixture_Demo_throgh_class1(self):\n",
    "        print(\"This will execute steps in fixtures demo throgh class\")\n",
    "    def test_Fixture_Demo_throgh_class2(self):\n",
    "        print(\"This will execute steps in fixtures demo throgh class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:This is a debug statement which is executed\n",
      "INFO:root:This are some information statement\n",
      "DEBUG:root:This is a debug statement which is executed\n",
      "WARNING:root:Something gone wrong\n",
      "ERROR:root:A major error has happend please check\n",
      "CRITICAL:root:Critical issue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                     [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m8 passed\u001b[0m\u001b[32m in 0.11s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest\n",
    "@pytest.fixture()\n",
    "def dataLoad():\n",
    "    print(\"User profile has been created\")\n",
    "    print(\"Please check the details\")\n",
    "    print(\"Date 06-Dec-2021\")\n",
    "    return [\"Rahul\",\"Maurya\"] # This will be return in output or help in grabing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User profile has been created\n",
      "Please check the details\n",
      "Date 06-Dec-2021\n",
      "['Rahul', 'Maurya']\n",
      "Rahul\n",
      "Maurya\n",
      "Rahul Maurya\n",
      "\u001b[32m.\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k test_editprofile -s\n",
    "@pytest.mark.usefixtures(\"dataLoad\")\n",
    "class TestExample2:\n",
    "    def test_editprofile(self,dataLoad): # Need to pass method name if we want to grab and return the data\n",
    "        print(dataLoad)\n",
    "        print(dataLoad[0]) # Passing result by index\n",
    "        print(dataLoad[1])\n",
    "        print(dataLoad[0],dataLoad[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                      [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m7 passed\u001b[0m\u001b[32m in 0.13s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest\n",
    "@pytest.fixture(params=[\"chrome\",\"firefox\"]) # Making test for different browers\n",
    "def crossBrowser(request):\n",
    "    return request.param       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrome\n",
      "\u001b[32m.\u001b[0mfirefox\n",
      "\u001b[32m.\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m5 deselected\u001b[0m\u001b[32m in 0.04s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k test_crossBrowser0 -s \n",
    "def test_crossBrowser0(crossBrowser): # No need self as it is no class\n",
    "    print(crossBrowser)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                      [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m7 passed\u001b[0m\u001b[32m in 0.08s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest\n",
    "@pytest.fixture(params=[(\"chrome\",\"Rahul\"),(\"firefox\",\"Maurya\")]) # When you have multiple value for different browser\n",
    "def crossBrowser(request):\n",
    "    return request.param       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chrome', 'Rahul')\n",
      "\u001b[32m.\u001b[0m('firefox', 'Maurya')\n",
      "\u001b[32m.\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m5 deselected\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k test_crossBrowser1 -s \n",
    "def test_crossBrowser1(crossBrowser): # No need self as it is no class\n",
    "    print(crossBrowser)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Html reports for pytest testcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chrome', 'Rahul')\n",
      "\u001b[32m.\u001b[0m('firefox', 'Maurya')\n",
      "\u001b[32m.\u001b[0m\n",
      "---------- generated html file: file://C:\\Users\\Rahul Maurya\\Desktop\\edureka\\report.html ----------\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m5 deselected\u001b[0m\u001b[32m in 0.06s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k test_crossBrowser1 -s --html=report.html\n",
    "# Adding --html=report.html help you to generate html report of your test\n",
    "def test_crossBrowser1(crossBrowser): \n",
    "    print(crossBrowser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger=logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n",
      "DEBUG:root:This is a debug statement which is executed\n",
      "INFO:root:This are some information statement\n",
      "DEBUG:root:This is a debug statement which is executed\n",
      "WARNING:root:Something gone wrong\n",
      "ERROR:root:A major error has happend please check\n",
      "CRITICAL:root:Critical issue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m7 deselected\u001b[0m\u001b[32m in 0.05s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k test_loggingDemo -s\n",
    "def test_loggingDemo():\n",
    "    fileHandler=logging.FileHandler(\"logfile2.log\")\n",
    "    formatter=logging.Formatter(\"%(asctime)s :%(levelname)s :%(name)s :%(message)s\")\n",
    "    fileHandler.setFormatter(formatter)\n",
    "    logger.addHandler(fileHandler)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.debug(\"This is a debug statement which is executed\")\n",
    "    logger.info(\"This are some information statement\")\n",
    "    logger.debug(\"This is a debug statement which is executed\")\n",
    "    logger.warning(\"Something gone wrong\")\n",
    "    logging.error(\"A major error has happend please check\")\n",
    "    logging.critical(\"Critical issue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "class BaseClass:\n",
    "    def getLogger(self):\n",
    "        loggerName = inspect.stack()[1][3]\n",
    "        logger = logging.getLogger(loggerName)\n",
    "        fileHandler=logging.FileHandler(\"logfile4.log\")\n",
    "        formatter=logging.Formatter(\"%(asctime)s :%(levelname)s :%(name)s :%(message)s\")\n",
    "        fileHandler.setFormatter(formatter)\n",
    "        logger.addHandler(fileHandler)\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        logger.debug(\"This is a debug statement which is executed\")\n",
    "        logger.info(\"This are some information statement\")\n",
    "        logger.debug(\"This is a debug statement which is executed\")\n",
    "        logger.warning(\"Something gone wrong\")\n",
    "        logging.error(\"A major error has happend please check\")\n",
    "        logging.critical(\"Critical issue\")\n",
    "        return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n",
      "DEBUG:test_editprofile:This is a debug statement which is executed\n",
      "INFO:test_editprofile:This are some information statement\n",
      "DEBUG:test_editprofile:This is a debug statement which is executed\n",
      "WARNING:test_editprofile:Something gone wrong\n",
      "ERROR:root:A major error has happend please check\n",
      "CRITICAL:root:Critical issue\n",
      "INFO:test_editprofile:Rahul\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User profile has been created\n",
      "Please check the details\n",
      "Date 06-Dec-2021\n",
      "Maurya\n",
      "\u001b[32m.\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m7 deselected\u001b[0m\u001b[32m in 0.09s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k test_editprofile -s\n",
    "@pytest.mark.usefixtures(\"dataLoad\")\n",
    "class TestExample2(BaseClass):\n",
    "    def test_editprofile(self,dataLoad): # Need to pass method name if we want to grab and return the data\n",
    "        log=self.getLogger()\n",
    "        log.info(dataLoad[0])\n",
    "        print(dataLoad[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n",
      "DEBUG:test_editprofile:This is a debug statement which is executed\n",
      "INFO:test_editprofile:This are some information statement\n",
      "DEBUG:test_editprofile:This is a debug statement which is executed\n",
      "WARNING:test_editprofile:Something gone wrong\n",
      "ERROR:root:A major error has happend please check\n",
      "CRITICAL:root:Critical issue\n",
      "INFO:test_editprofile:Rahul\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "---------- generated html file: file://C:\\Users\\Rahul Maurya\\Desktop\\edureka\\report.html ----------\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m7 deselected\u001b[0m\u001b[32m in 0.11s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k test_editprofile --html=report.html\n",
    "@pytest.mark.usefixtures(\"dataLoad\")\n",
    "class TestExample2(BaseClass):\n",
    "    def test_editprofile(self,dataLoad): # Need to pass method name if we want to grab and return the data\n",
    "        log=self.getLogger()\n",
    "        log.info(dataLoad[0])\n",
    "        print(dataLoad[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End to end testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m\u001b[33m\u001b[1m1 deselected\u001b[0m\u001b[33m in 0.02s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k invoke_setup -s \n",
    "@pytest.fixture(scope=\"class\")\n",
    "def invoke_setup(request):\n",
    "    driver=webdriver.Chrome(executable_path=\"D:\\\\cv\\\\N\\\\chromedriver.exe\")\n",
    "    driver.get(\"https://rahulshettyacademy.com/angularpractice/\")\n",
    "    driver.find_element_by_xpath(\"//a[contains(text(),'Shop')]\").click()\n",
    "    request.cls.driver=driver # use this methos because return and yield not work together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as E\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iphone X\n",
      "Samsung Note 8\n",
      "Nokia Edge\n",
      "Blackberry\n",
      "Your purchase item is Blackberry\n",
      "Total Price On Site ₹. 50000\n",
      "Total Amount Need TO Pay ₹. 50000\n",
      "×\n",
      "Success! Thank you! Your order will be delivered in next few weeks :-).\n",
      "\u001b[32m.\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 25.84s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k test_e2e -s\n",
    "@pytest.mark.usefixtures(\"invoke_setup\")\n",
    "class Testone():\n",
    "    def test_e2e(self,invoke_setup):\n",
    "        items_avilable=self.driver.find_elements_by_xpath(\"//h4[@class='card-title']\")\n",
    "        l=[]\n",
    "        for i in items_avilable:\n",
    "            print(i.text)\n",
    "            l.append(i.text)\n",
    "            if i.text==\"Blackberry\":\n",
    "                c=l.index(\"Blackberry\")\n",
    "                Click_to_add=self.driver.find_elements_by_xpath(\"//button[@class='btn btn-info']\")\n",
    "                Click_to_add[c].click()\n",
    "                self.driver.find_element_by_xpath(\"//a[@class='nav-link btn btn-primary']\").click()\n",
    "                c=self.driver.find_element_by_xpath(\"//a[contains(text(),'Blackberry')]\").text\n",
    "                print(\"Your purchase item is\",c)\n",
    "                c1=self.driver.find_element_by_xpath(\"//tbody/tr[1]/td[3]/strong[1]\").text\n",
    "                print(\"Total Price On Site\",c1)\n",
    "                c2=self.driver.find_element_by_xpath(\"//tbody/tr[1]/td[4]/strong[1]\").text\n",
    "                print(\"Total Amount Need TO Pay\",c2)\n",
    "                if c1==c2:\n",
    "                    self.driver.find_element_by_xpath(\"//tbody/tr[3]/td[5]/button[1]\").click()\n",
    "                    self.driver.find_element_by_xpath(\"//input[@id='country']\").send_keys(\"INDIA\")\n",
    "                    time.sleep(5)\n",
    "                    self.driver.find_element_by_xpath(\"//a[contains(text(),'India')]\").click()\n",
    "                    time.sleep(4)\n",
    "                    self.driver.find_element_by_xpath(\"//input[@class='btn btn-success btn-lg']\").click()\n",
    "                    time.sleep(2)\n",
    "                    c=self.driver.find_element_by_xpath(\"//div[@class='alert alert-success alert-dismissible']\").text\n",
    "                    time.sleep(2)\n",
    "                    print(c)\n",
    "                    self.driver.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m1 deselected\u001b[0m\u001b[32m in 4.60s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest -k TestHomePage -s\n",
    "class TestHomePage():\n",
    "    def test_form_submit(self):\n",
    "        driver=webdriver.Chrome(executable_path=\"D:\\\\cv\\\\N\\\\chromedriver.exe\")\n",
    "        driver.get(\"https://rahulshettyacademy.com/angularpractice/\")\n",
    "        driver.find_element_by_css_selector(\"[name='name']\").send_keys(\"Rahul\")\n",
    "        driver.find_element_by_name(\"email\").send_keys(\"rahulmaurya1997@gmail.com\")\n",
    "        driver.close()\n",
    "        \n",
    "       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data from excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl # importing package for excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "book=openpyxl.load_workbook(\"D:\\\\Python_Demo.xlsx\") # Just loading the data from workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "Python_Demo=book.active # Python_Demo is name of sheet from which data need to be driven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell=Python_Demo.cell(row=1,column=2) # Giving information about row and column to cell number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Name'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell.value # pring value in cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "Python_Demo.cell(row=2,column=2).value=\"Rahul\" # Wring value to a specific cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rahul\n"
     ]
    }
   ],
   "source": [
    "cell=Python_Demo.cell(row=2,column=2) # Checking the value entered in above step\n",
    "print(cell.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Python_Demo.max_row # Print maximum number of row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Python_Demo.max_column # Print maximum number of column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testcase1\n"
     ]
    }
   ],
   "source": [
    "c=Python_Demo[\"A2\"].value # Print by cell number\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info\n",
      "First Name\n",
      "Last Name \n",
      "Email\n",
      "Testcase1\n",
      "Rahul\n",
      "b\n",
      "c\n",
      "Testcase2\n",
      "Rahul \n",
      "Maurya\n",
      "rahulmaurya1997@gmail.com\n",
      "t1\n",
      "a\n",
      "b\n",
      "c\n",
      "t1\n",
      "A\n",
      "B\n",
      "C\n",
      "t1\n",
      "a\n",
      "b\n",
      "c\n",
      "t1\n",
      "A\n",
      "B\n",
      "C\n",
      "t1\n",
      "a\n",
      "b\n",
      "c\n",
      "Testcase4\n",
      "A\n",
      "B\n",
      "C\n",
      "t1\n",
      "a\n",
      "b\n",
      "c\n",
      "t1\n",
      "A\n",
      "B\n",
      "C\n",
      "t1\n",
      "a\n",
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "# Printing all the value\n",
    "for i in range(1,Python_Demo.max_row+1):\n",
    "    for j in range(1,Python_Demo.max_column+1):\n",
    "        print(Python_Demo.cell(row=i,column=j).value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testcase4\n",
      "A\n",
      "B\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "# Printing only specific row value\n",
    "for i in range(1,Python_Demo.max_row+1):\n",
    "    if Python_Demo.cell(row=i,column=1).value==\"Testcase4\":\n",
    "        for j in range(1,Python_Demo.max_column+1):\n",
    "            print(Python_Demo.cell(row=i,column=j).value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "# Printing only specific row value but not first row value\n",
    "for i in range(1,Python_Demo.max_row+1):\n",
    "    if Python_Demo.cell(row=i,column=1).value==\"Testcase4\":\n",
    "        for j in range(2,Python_Demo.max_column+1):\n",
    "            print(Python_Demo.cell(row=i,column=j).value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Info': 'Testcase2', 'First Name': 'Rahul ', 'Last Name ': 'Maurya', 'Email': 'rahulmaurya1997@gmail.com'}\n"
     ]
    }
   ],
   "source": [
    "# Storeing data into a dictionary of a particular row\n",
    "dict1={}\n",
    "for i in range(1,Python_Demo.max_row+1):\n",
    "    if Python_Demo.cell(row=i,column=1).value==\"Testcase2\":\n",
    "        for j in range(1,Python_Demo.max_column+1):\n",
    "            dict1[Python_Demo.cell(row=1,column=j).value]=Python_Demo.cell(row=i,column=j).value\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
